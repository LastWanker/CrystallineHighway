结晶高速公路的代码结构围绕“寻找驱动建构”的主干流程展开，核心模块集中在 src/crystalline_highway/core 下。整体上可以理解为三个层次：文本入口与拆分、记忆建构与固化、检索扩散与输出。每一层都对应指导文件中的关键设定，并在实现中刻意保留“可扩展而不锁死”的接口。

在文本入口层，segmentation.py 与 recitation.py 共同承担“如何把原始文本拆成可背诵单元”的职责。segmentation.py 提供中文分词与句法层级拆分，默认优先使用 jieba，LTP 可用时亦可接入，而当外部工具不可用时退化到内置分词规则。这一层的策略是：最小词素用于预注册，短语、短句、长句、段落与全文都必须收敛，当前层级全部注册完成后才推进下一层背诵。recitation.py 不直接做分词，而是基于 segmentation.py 返回的 display_text 与 normalized_text 构建背诵计划，从而同时满足“寻找时忽略标点”和“输出时保留标点”的双重要求。

在记忆建构层，memory_system.py 是主入口。它持有 Registry、Graph 与 Store 并串起完整流程：写入时调用 _ensure_instance，按动态容忍度寻找或新建实例；连接记录在 Graph 里，边计数作为固化燃料；当计数达到阈值时触发固化，生成新元并建立纵向索引路径，同时抽走旧路的计数。固化阈值采用 log2 递增策略，不应期标志用来阻止刚固化的实例立刻参与下一次固化。Registry 负责元与实例的注册，使用规范化文本作为词典键，确保标点不影响寻找，而 display_text 则保留用于输出。

在检索扩散层，memory_system.py 的 retrieve 逻辑实现 TTL 扩散与交汇排序。系统通过 SessionState 记录点亮次数与来源，按配额筛选短句、长句、段落与全文候选；这一部分严格遵循“前台不做大半径跳跃”的原则，后续若要扩展，可在该层加入后台背诵调度与 hubness 折寿策略。模型层（models 目录）提供 MetaEntry、InstanceNode 与 Graph 的数据结构，storage 目录仅提供内存存储的最小实现，方便未来替换为持久化存储。

词向量相关逻辑位于 word_vectors.py。该模块将腾讯词向量视作“星图/范畴场”，提供词向量查询与聚合，并实现对 .bin 文件的索引化加载。其输出直接影响 Registry 创建实例时的范畴偏移，从而在空间中形成更易收敛的“粗语义力场”。为了避免分词器与词向量的耦合，该模块只依赖通用的分词入口，并尽量保持可替换。

总体而言，这套结构强调“分离职责”：文本拆分只负责把文本变成可背诵的单元，记忆建构负责寻找与固化规则，检索扩散负责 TTL 与交汇排序，词向量仅用于提供弱方向性。这样的结构保证了未来可以在不破坏核心哲学的前提下引入更复杂的分词器、更稳健的持久化存储与更精细的检索策略。
