————————————————————————————————
结晶高速公路（Crystalline Highway）
一种“寻找驱动建构”的外部记忆系统设想（概念优先 / 机械优先 / 私人定制）
————————————————————————————————

一、问题的起点：上下文不是记忆
当前大语言模型面对的“长期记忆”问题，本质上并不是存储能力不足，而是上下文机制与记忆本质的错位。

模型的上下文窗口是一次性、线性的、按 token 计费的。它更像“当前工作记忆”，而不是可反复调用、可被结构化访问的长期记忆。即便通过工程手段扩大窗口，或者人为塞入几十万、上百万 token，其结果也只是把“回忆”误当成了“重读”。

如果每一次回应都需要把几百万 token 当作上下文整体输入，那么显存、算力和延迟都会迅速失控。这条路走到尽头，只会让显卡比金子还贵。

因此，问题不在于“如何塞下更多文本”，而在于：如何在不加载全部历史的前提下，仍然能够精准地“想起”其中某一次、某一段、某一个事件。
这不是存储问题，而是记忆形成与提取机制的问题。


二、对现有方案的反思：检索并不等于记忆
常见思路是检索：关键词匹配、向量相似度、分层摘要、定期总结、RAG。
它们工程上有效，但普遍暗含一个前提：记忆是“静态文本”，检索是“事后查询”。

于是问题接踵而至：
    - 同一个事件在不同时间反复发生，如何区分？
    - 一个关键词匹配到的历史越来越多，如何剪枝？
    - 摘要不断摘要，信息熵不断丢失，最终剩下的还是模板化陈述。
    - 高频词成为枢纽，向量空间变成噪声海。

更重要的是：这些方法往往在“读取阶段”付出高昂代价，而“写入阶段”几乎什么都不做。
它们没有把“未来如何被想起”这件事，提前编码进记忆形成的过程里。


三、结晶高速公路的基本立场（核心哲学）
结晶高速公路不是一个更聪明的检索系统，也不是一个内嵌的智能模型。
它是私人定制化的、机械性的、基于统计与图结构的记忆系统，目标只有一个：
让未来提取变得快速、精准、低成本——哪怕为此在记忆形成阶段付出更多“功夫”。

核心立场压缩为一句话：
    寻找即建构。
    连接是寻找留下的痕迹，而不是事前审批的结果。

这也意味着：系统记录的不是“文本本身”，而是“围绕文本发生过的寻找事件”。


四、系统里的基本对象：元、实例、星图（初始脑）
4.1 元（记忆的基本单位，但不是 token）
元可以是：一个字、一个词、一个语素、一个短语、一句话、一段对话、一首诗。
元的大小本身不重要；重要的是：它是否成为过“寻找的目标”。

    元不是由预先规定的粒度决定的，而是由使用过程中的路径频率决定的。
    元的身份不是数据库 ID，而是其在一个固定低维空间中的向量位置（以及其在图里的关系）。

4.2 实例（同一个元的多个“具体落点”）
    元不是只有一个点。尤其是高频元，往往会拥有很多实例。
    “实例”是：一次寻找没命中，于是在当前上下文附近新建出来的那个具体点。
    实例数量不是噪声，而是结构的一部分：通过“复制/分身”实现去中心化。

4.3 初始脑（星图）
    系统初始化时，为基础词元赋予一个大致的范畴向量（粗略、稳定、可长期复用）。
    同时，每个元初始化一个全局统计频率（来自语言整体的统计近似，而非当前用户）。


五、语义空间与范畴场（低维、粗轴、用于“力场”而非精确语义）
系统暂定使用外部词向量：腾讯 200 维中文词向量。
这意味着我们不再依赖手工定义的粗轴，而是以已有语义空间作为“范畴力场”的来源。
它仍然只承担弱牵引与方向性，不承担精确语义推理：
    - 给新建提供方向性（别完全随机）
    - 给长期运行提供弱牵引（别彻底漂到不可收敛）


六、动态容忍度：频率决定搜索半径
每个元都有一个动态容忍度，操作层面等价于“搜索半径”：
在多大范围内算“找到了”。

动态容忍度与全局频率强烈负相关：
    高频元 → 容忍度极小
    低频元 → 容忍度极大

概念式（仅强调单调关系，不强调具体函数）：
    radius = K / (log(global_freq) + C)

重要澄清：
    容忍度不是“是否允许连接”的阈值，
    容忍度是“多像/多近算命中”的定义。


七、核心机制：寻找驱动建构（命中 or 新建，然后留下连接）
系统处理顺序文本时，不是“先找到所有元，再决定怎么连”。
流程是：我当前在元 A，我需要下一个概念 B，于是启动一次“寻找 B”的行为。

7.1 基本寻找规则
    - 以 A 的位置为中心（上下文中心）
    - 以 B 的动态容忍度为半径
    - 在空间中搜索是否存在某个 B 的实例

    若命中：
        使用该实例；A → B 的连接自然成立。
    若未命中：
        在 A 附近当场新建一个 B 的实例；
        新建位置 = A 坐标 + 轻微扰动 + B 的范畴偏移；
        然后连接 A → 新 B。

    连接不是被批准的，而是一次寻找完成后留下的痕迹。

7.2 多个命中怎么办（必须补的“择优规则”，否则会漂移）
    当半径内出现多个 B 实例，必须确定选谁，否则同样输入会走出不同路，结构不可重复。
    概念上最朴素的一条择优顺序：
        先选更近的；
        近似时选“更常被走到/更常被用到”的；
        再并列才允许随机或轮换。
    这不是浪漫细节，是系统可复现性的地基。

7.3 寻找时优先更长的词条
    每次寻找时，优先选择字典中更长的词条。
    例如剩余字符串是 “C D”，若字典里已有 “CD”，则优先走 “CD”。

7.4 新建时“范畴偏移”与频率的关系（消除歧义的版本）
    新建落点由三股因素共同决定：
        - 贴上下文 A（核心）
        - 扰动（非纯随机，可带“向稀疏发展”的偏好）
        - 范畴偏移（提供方向性）

    但范畴偏移的作用不应一刀切：
        - 高频元：范畴偏移应显著弱化（避免被拉成中心云团，避免成为枢纽）
        - 低频元：范畴偏移相对更能发挥作用（更稳定、更像锚点）


八、高频元与低频元的命运分化（用复制实现去中心化）
高频元（如“的”“有”“人”）：
- 容忍度极小，几乎永远找不到现成实例，因而被不断新建。
- 结果是实例数量极多、分布极其分散、每个实例只服务于极局部的上下文。
- 没有任何一个“的”能成为交通枢纽。

低频元（如“硒”“牛顿”“万有引力”）：
    - 容忍度极大，实例极少、位置稳定。
    - 大多数寻找都会命中同一个实例，自然成为跨上下文、跨时间的锚点。

这是通过“复制”而非“限制”实现去中心化的机制。


九、顺序文本如何转化：寻找事件的遗迹（过程化石）
例如文本：“牛顿 发现 了 万有引力”。

系统中不是拆成 token，而是转化为一连串寻找事件：
    从起点寻找“牛顿”，从“牛顿”寻找“发现”，从“发现”寻找“万有引力”。

每一次寻找都会留下连接。
路径不是被设计出来的，而是被走出来的。


十、通行计数与路径计数：路网为什么会“长出结构”
这里必须明确：边/路径被走过的次数不是可选项，而是核心。
因为固化来自“这条路被走多了”。

10.1 路径/边被走过的次数
    当从 A 走到 B：
        A→B 这条边的通行次数增加。
    这是“寻找事件的沉积”，是固化的直接燃料。

10.2 节点被路过的次数（与边次数相关，但不等价）
    节点也会累积“被经过/被使用”的次数。
    它与边次数互相关联，但不能混为一谈（后面会专门分清几种“频率/次数”）。


十一、重复、背诵与固化：高速公路如何诞生
单次路径不重要，重要的是同一条或高度相似的路径是否被反复走过。
系统允许、甚至鼓励对重要内容进行多次导入：
先导入短句，再导入长句，再导入整段，再在不同时间重复导入——这是对“背诵”的模拟。

11.1 固化触发（阈值递增 + 固化元数量标签）
    当某一段连续路径（只允许二元）通行次数超过阈值时，触发固化：
        将这段路径上的元序列，打包为一个新的、更大的元。
    固化阈值递增规则：
        以“固化元数量标签”为基础，阈值 = ceil(log2(数量)) + 1
        例：2 元阈值 = 2；4 元阈值 = 3；8 元阈值 = 4 ...
    固化元数量标签在固化时相加，暂时绑定在词典元上；若出现同句不同数量，允许绑定实例。
    这个新元实例极少，直接指向完整原始文本——这就是“高速公路”。

11.2 旧路与新路同时存在（但计数会迁移/削减）
    固化不会删除旧路径：
        旧连接仍然存在（细节丰富，慢）。
    但旧路径的通行计数会被削减（被“抽走”）：
        走得多的那段路被打包成新元后，
        旧边上的“被走次数”会转移一部分到新固化元的“被使用/被路过”上。
    于是系统中同时存在：
        乡间小路（细节丰富，慢）
        高速公路（概括性强，快）

11.3 背诵调度（先拆分，再倒序输入）
    背诵过程采用拆分控制：
        先拆成长句、短句、词组，再按照倒序输入（词组→短句→长句→整段→全文）。
    每一层输入会循环直到“收敛”：
        输入的条目被注册为元或被固化，视为收敛完成。
    收敛后会给该元打标签，用于检索输出的分类与配额。

11.4 固化后的补充设定（引入对数缓和）
    固化后的元在构建时，其被寻找的容忍度采用对数/开方缓和的倍率，不再直接使用乘积暴涨。
    固化后的维度位置暂定为来源子元维度向量的平均值，但整体向更离心、更稀疏的空间方向偏移。
    由于固化元的容忍度极高、触发频率极低，其对应的场系数将非常大，
    因此在语义空间中的位置高度稳定、难以漂移。
    （新的实现会以 log2(数量+1) 作为倍率缓和。）

11.5 固化层级（贴标签，不是无限增几何维度）
    固化会自然产生层级感（实验性讲法，不要求刻板）：
        1 次固化更像短语，
        2 次固化更像短句，
        3 次固化更像长句，
        4 次固化更像段落，
        5 次固化更像长文。
    层级的用途：
        - 防止无关东西过度贴近甚至重合（至少先别在同一个候选池里硬比）
        - 寻路过滤：想找明显更高层的条目，不应在最低层全空间乱扫
        - 可能涌现新语义（机械涌现，先不强控）

11.6 固化不应期（防止连续固化）
    同一次输入中，若某实例刚参与固化，会进入一次性不应期：
        - 下一次潜在固化会被抵消并跳过
    目的：避免 “AB 刚固化就立刻触发 ABC” 的连锁固化。


十二、记忆读取：寻找的再现（检索态以 TTL 与交集为主）
读取不是反向检索，而是再次启动寻找。
查询被解析为若干元，每一个都是起点。

12.1 点亮与扩散
    从起点出发，电信号沿连接扩散，但受 TTL 限制。
    多个信号在网络中交汇，被多次触及的节点和路径被强激活，
    尤其是固化组块元，往往成为交集焦点。

    系统最终返回的不是“节点本身”，而是这些节点所指向的完整历史文本。

    hubness 折寿规则暂不启用（视为 0 惩罚）。

12.2 会话态点亮：从 0 开始、不采用衰减
    点亮计数是会话内注意力过程：
        新开始一次对话前，各节点点亮可以视作平的（从 0 起步）。
        随对话进行，被触达的地方逐步点亮。
    当前版本不采用衰减策略，保持计数纯粹可追踪。

12.3 检索态不推荐“按半径跳跃式全局找路”
    检索态的主要控制应是“步数/TTL + 多源交汇剪枝”。
    “没路”的含义：
        要么真没有，
        要么背诵/构筑得不够。
    按半径做大范围跳跃代价很大，应更适合：
        丢给后台慢慢去背诵、去补路（像小助理闲着把旧事务背一背）。

12.4 输出排序（固定配额）
    暂定输出配额：
        9 个关键短句
        6 个关键长句
        3 个可能相关段落
        1 个相关记忆
        2 个可能相关的记忆
    规则：按点亮次数排序，且只从“已收敛并打标签”的条目中选取对应类别。


十三、私人高频固化元：允许口头禅成为必经之路，也允许它继续演化
你给过典型案例：“鸡你太美”。

13.1 口头禅成为必经之路（并非必然坏事）
    “鸡你”“太美”的路径被走多了，触发固化成更高层级的元“鸡你太美”。
    之后用户频繁使用，使其在路网中“电阻低”，很多寻路会优先经过它。
    这体现用户习惯，很有个人特色。
    最终检索输出仍以：
        更常被点亮的、更高层级的（更像事实整体）优先，
    口头禅入选也无伤大雅：用户就是爱说。

13.2 但固化元不会永远低频：当它在私人语料里变成“超常见”，就应被当作高频对待
    这就要求维护“字典注册”机制：
        字典最初给的是基础频率（全局近似）。
        但当某些固化短语在私人统计中超过阈值，应允许注册为“新常见元”。

    一旦“鸡你太美”在私人统计里变得像高频词：
        容忍度随其频率升高而降低（更局部、更挑剔）
        当附近找不到它时，允许新建新的“鸡你太美”实例（分身）
        于是它不再是唯一的宇宙中心，而是多个上下文局部的口头禅碎片

    同时保留你原来的闭环要点：
        即使它范畴场强度可能高，偏移量仍会随频率被压制，
        因而不会被强行拉成中心云团。


十四、几种“频率/次数”必须分清（渊源相互关联，但不是一回事）
这里给出概念分层（不强行用变量名）：

14.1 字典频率（全局统计近似 + 私人注册更新）
    冷启动的基础频率来自语言整体统计。
    私人使用中，某些固化短语/句子可达到阈值后被注册为“超常见”，使其进入字典体系。

14.2 构筑/背诵时的“节点被路过次数”
    表示：在建设记忆路网的过程中，这个元被经过/被使用的强度。
    它会影响未来寻路倾向、以及某些固化块的“常用性”。

14.3 构筑/背诵时的“路径/边被走过次数”（固化燃料）
    表示：这条具体连接被走过多少次。
    它是触发固化的直接依据。
    固化发生时，边次数会被削减，并迁移到新固化元的“被使用强度”上（抽走机制）。

14.4 检索/对话时的“点亮次数”
    会话态注意力计数：用于多源交汇、交集剪枝、候选排序。
    它不等于字典频率，也不等于构筑时的经过次数，更不等于边次数。


十五、系统的本质（仍然保持旧 README 的判断）
结晶高速公路不是图数据库，不是向量库，不是知识图谱。
它是一个记录“寻找事件”的过程化石网络。
网络结构不是被设计的，而是历史本身的沉积。

它的目标从来不是让系统“记住一切”。
而是让真正发生过的寻找，在未来仍然有被再次点亮的可能：
    不是加载历史，而是回到曾经走过的路。


十六、未来问题（保留，但不动摇当前哲学）
16.1 中频概念的“幽灵实例”
中频概念可能产生多个语义相近但未完全收敛的实例。
需要慢速、非强制的再牵引机制（未来问题，不是否定当前哲学）。

16.2 点亮衰减与维护策略
    点亮是否只在会话内清零、是否跨会话保留残余热度、基于会话进程还是现实时间——可按用途决定。

16.3 固化阈值与层级规则
    不同层级的固化阈值如何设定（短语/短句/段落/长文），以及固化后“乘积极端容忍度”如何逐步松绑到可持续状态。

16.4 后台背诵的调度策略
    前台检索发现“没路/路太薄”时，后台应如何选取补路任务、用多大代价、在何种空闲时机执行。


结语
结晶高速公路的思路是：把“未来如何被想起”提前编码进写入阶段。
让连接成为寻找的沉积，让高速公路成为背诵的结晶。

最终交给语言模型的不是海量历史，而是被路网筛出来的、可追溯的、与当下问题相干的那几段原始文本。
